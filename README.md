<p align="center">
  <img src="public/vite.svg" width="64" alt="CampusOS Logo" />
</p>

<h1 align="center">CampusOS</h1>

<p align="center">
  <strong>AI-Powered Asset Orchestration Platform for College Students</strong>
</p>

<p align="center">
  <a href="#-quick-start">Quick Start</a> ‚Ä¢
  <a href="#-how-it-works">How It Works</a> ‚Ä¢
  <a href="#-architecture">Architecture</a> ‚Ä¢
  <a href="#-api-reference">API Reference</a> ‚Ä¢
  <a href="#-project-structure">Project Structure</a> ‚Ä¢
  <a href="#-screenshots">Screenshots</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/React-18-61DAFB?logo=react&logoColor=white" alt="React" />
  <img src="https://img.shields.io/badge/TypeScript-5.8-3178C6?logo=typescript&logoColor=white" alt="TypeScript" />
  <img src="https://img.shields.io/badge/Vite-5.4-646CFF?logo=vite&logoColor=white" alt="Vite" />
  <img src="https://img.shields.io/badge/Express-4.x-000000?logo=express&logoColor=white" alt="Express" />
  <img src="https://img.shields.io/badge/TailwindCSS-3.4-06B6D4?logo=tailwindcss&logoColor=white" alt="Tailwind" />
</p>

---

## üéØ What Is CampusOS?

CampusOS transforms natural language descriptions into **ready-to-use digital assets** ‚Äî posters, landing pages, and presentations ‚Äî tailored for college students. Describe what you need, and the AI handles the rest.

**No Supabase. No Gemini. Pure OpenAI.**

### Supported Creation Types

| Type | What You Get | Example Prompt |
|------|-------------|----------------|
| üé™ **Event Promotion** | Posters, flyers, social media content | *"Create a poster for our college tech fest TechNova 2026"* |
| üåê **Landing Pages** | Complete HTML/CSS websites | *"Build a landing page for our coding club showcasing workshops"* |
| üìä **Presentations** | Slide decks, pitch presentations | *"Make a pitch deck for our AI-powered study planner startup"* |

---

## üì∏ Screenshots

### Home Page
> Hero section with gradient effects, feature cards, and call-to-action

![Home Page](docs/screenshots/homepage.png)

### Create Page
> AI prompt input with example suggestions and keyboard shortcut

![Create Page](docs/screenshots/create-page.png)

### History Page
> Browse and manage your past creations (stored locally)

![History Page](docs/screenshots/history-page.png)

---

## üîÑ How It Works

The entire creation flow runs through **3 AI-powered stages**, each calling a dedicated API endpoint powered by OpenAI's GPT-4o-mini:

```mermaid
flowchart LR
    A["üó£Ô∏è User Prompt"] -->|Natural Language| B["üß† Interpret Intent"]
    B -->|Structured Intent| C["üìã Generate Pipeline"]
    C -->|Execution Plan| D["‚ö° Generate Assets"]
    D -->|Text / Design / Code| E["üì¶ Ready-to-Use Output"]

    style A fill:#1e1b4b,stroke:#a855f7,color:#e2e8f0
    style B fill:#1e1b4b,stroke:#6366f1,color:#e2e8f0
    style C fill:#1e1b4b,stroke:#3b82f6,color:#e2e8f0
    style D fill:#1e1b4b,stroke:#06b6d4,color:#e2e8f0
    style E fill:#1e1b4b,stroke:#10b981,color:#e2e8f0
```

### Stage 1 ‚Äî Intent Interpretation

The user types a natural language description. The AI parses it into a structured `ParsedIntent`:

```mermaid
flowchart TD
    Input["User types: 'Create a poster for our\ncollege tech fest TechNova 2026\nwith a futuristic theme'"]
    
    Input --> Parse["GPT-4o-mini\n(JSON mode)"]
    
    Parse --> Output["ParsedIntent"]
    
    Output --> Type["type: event_promotion"]
    Output --> Title["title: TechNova 2026"]
    Output --> Audience["audience: college students"]
    Output --> Tone["tone: energetic"]
    Output --> Elements["elements:\n- hero headline\n- event date\n- registration CTA\n- speaker lineup\n- venue details"]
    
    style Input fill:#1e1b4b,stroke:#a855f7,color:#e2e8f0
    style Parse fill:#312e81,stroke:#6366f1,color:#e2e8f0
    style Output fill:#1e1b4b,stroke:#3b82f6,color:#e2e8f0
    style Type fill:#1e293b,stroke:#475569,color:#94a3b8
    style Title fill:#1e293b,stroke:#475569,color:#94a3b8
    style Audience fill:#1e293b,stroke:#475569,color:#94a3b8
    style Tone fill:#1e293b,stroke:#475569,color:#94a3b8
    style Elements fill:#1e293b,stroke:#475569,color:#94a3b8
```

### Stage 2 ‚Äî Pipeline Generation

The parsed intent is sent to the AI to create an **ordered execution plan**:

```mermaid
flowchart TD
    Intent["ParsedIntent"] --> Plan["GPT-4o-mini\nPipeline Planner"]
    
    Plan --> S1["Step 1: Content Copy\n(type: text)"]
    Plan --> S2["Step 2: Design System\n(type: design)"]
    Plan --> S3["Step 3: Poster HTML\n(type: code)"]
    
    S1 -->|depends on| S2
    S2 -->|depends on| S3
    
    style Intent fill:#1e1b4b,stroke:#a855f7,color:#e2e8f0
    style Plan fill:#312e81,stroke:#6366f1,color:#e2e8f0
    style S1 fill:#1e293b,stroke:#f59e0b,color:#e2e8f0
    style S2 fill:#1e293b,stroke:#8b5cf6,color:#e2e8f0
    style S3 fill:#1e293b,stroke:#3b82f6,color:#e2e8f0
```

### Stage 3 ‚Äî Asset Generation

Each pipeline step is executed **sequentially**. The AI generates content based on the step type:

```mermaid
flowchart TD
    Step["Pipeline Step"] --> TypeCheck{"Step Type?"}
    
    TypeCheck -->|text| Text["üìù Copywriting Prompt\nHeadlines, descriptions,\ntaglines, CTAs"]
    TypeCheck -->|design| Design["üé® Design Spec Prompt\nColor palette, typography,\nlayout, spacing"]
    TypeCheck -->|code| Code["üíª Code Generation Prompt\nComplete HTML/CSS\nwith inline styles"]
    
    Text --> Asset1["GeneratedAsset\ncontentType: text"]
    Design --> Asset2["GeneratedAsset\ncontentType: markdown"]
    Code --> Asset3["GeneratedAsset\ncontentType: html"]
    
    style Step fill:#1e1b4b,stroke:#a855f7,color:#e2e8f0
    style TypeCheck fill:#312e81,stroke:#6366f1,color:#e2e8f0
    style Text fill:#1e293b,stroke:#f59e0b,color:#e2e8f0
    style Design fill:#1e293b,stroke:#8b5cf6,color:#e2e8f0
    style Code fill:#1e293b,stroke:#3b82f6,color:#e2e8f0
    style Asset1 fill:#1e293b,stroke:#10b981,color:#e2e8f0
    style Asset2 fill:#1e293b,stroke:#10b981,color:#e2e8f0
    style Asset3 fill:#1e293b,stroke:#10b981,color:#e2e8f0
```

---

## üèóÔ∏è Architecture

### System Architecture

```mermaid
graph TB
    subgraph Client["üñ•Ô∏è Frontend (React + Vite)"]
        UI["UI Components\nHeader, IntentInput,\nPipelineView, AssetCard"]
        Hook["useCreationEngine\n(State Machine)"]
        API["API Service\n(fetch client)"]
        Store["localStorage\n(History)"]
        
        UI <--> Hook
        Hook <--> API
        Hook <--> Store
    end
    
    subgraph Server["‚öôÔ∏è Backend (Express.js)"]
        Router["Express Router"]
        R1["POST /api/interpret-intent"]
        R2["POST /api/generate-pipeline"]
        R3["POST /api/generate-asset"]
        
        Router --> R1
        Router --> R2
        Router --> R3
    end
    
    subgraph AI["ü§ñ OpenAI API"]
        GPT["GPT-4o-mini"]
    end
    
    API -->|"HTTP (proxied by Vite)"| Router
    R1 --> GPT
    R2 --> GPT
    R3 --> GPT
    
    style Client fill:#0f172a,stroke:#6366f1,color:#e2e8f0
    style Server fill:#0f172a,stroke:#3b82f6,color:#e2e8f0
    style AI fill:#0f172a,stroke:#10b981,color:#e2e8f0
```

### Frontend Component Tree

```mermaid
graph TD
    App["App.tsx"] --> Header["Header"]
    App --> Router["React Router"]
    
    Router --> Home["Home Page\n/ "]
    Router --> Create["Create Page\n/create"]
    Router --> History["History Page\n/history"]
    Router --> NotFound["404 Page\n/*"]
    
    Create --> IntentInput["IntentInput\n(prompt textarea)"]
    Create --> Canvas["CreationCanvas"]
    
    Canvas --> Summary["IntentSummary\n(parsed intent card)"]
    Canvas --> Pipeline["PipelineView\n(step progress)"]
    Canvas --> Assets["AssetCard[]\n(generated outputs)"]
    
    style App fill:#312e81,stroke:#a855f7,color:#e2e8f0
    style Header fill:#1e293b,stroke:#6366f1,color:#e2e8f0
    style Router fill:#1e293b,stroke:#6366f1,color:#e2e8f0
    style Home fill:#1e293b,stroke:#3b82f6,color:#e2e8f0
    style Create fill:#1e293b,stroke:#3b82f6,color:#e2e8f0
    style History fill:#1e293b,stroke:#3b82f6,color:#e2e8f0
    style NotFound fill:#1e293b,stroke:#3b82f6,color:#e2e8f0
    style IntentInput fill:#1e293b,stroke:#10b981,color:#e2e8f0
    style Canvas fill:#1e293b,stroke:#10b981,color:#e2e8f0
    style Summary fill:#1e293b,stroke:#f59e0b,color:#e2e8f0
    style Pipeline fill:#1e293b,stroke:#f59e0b,color:#e2e8f0
    style Assets fill:#1e293b,stroke:#f59e0b,color:#e2e8f0
```

### State Machine ‚Äî `useCreationEngine`

The entire creation flow is managed by a state machine hook:

```mermaid
stateDiagram-v2
    [*] --> idle
    idle --> interpreting: User submits prompt
    interpreting --> planning: Intent parsed ‚úÖ
    interpreting --> error: API error ‚ùå
    planning --> generating: Pipeline created ‚úÖ
    planning --> error: API error ‚ùå
    generating --> generating: Step completed (loop)
    generating --> done: All steps complete ‚úÖ
    generating --> error: API error ‚ùå
    done --> idle: Reset
    error --> idle: Reset
```

---

## üöÄ Quick Start

### Prerequisites

- **Node.js 18+**
- **OpenAI API Key** ‚Äî [Get one here](https://platform.openai.com/api-keys)

### 1. Clone & Install

```bash
git clone https://github.com/nitinog10/Campus-Os.git
cd Campus-Os

# Install frontend dependencies
npm install

# Install server dependencies
cd server && npm install && cd ..
```

### 2. Configure OpenAI

```bash
# Edit the server .env file
# Replace sk-your-key-here with your actual OpenAI API key
```

`server/.env`:
```env
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxx
```

### 3. Run Both Servers

**Option A ‚Äî Two terminals:**

```bash
# Terminal 1: Frontend (http://localhost:5173)
npm run dev

# Terminal 2: Backend API (http://localhost:3001)
cd server && node server.js
```

**Option B ‚Äî Single command:**

```bash
npm run dev:all
```

### 4. Open the App

Navigate to **http://localhost:5173** and start creating!

---

## üì° API Reference

All endpoints accept and return JSON. The Vite dev server proxies `/api/*` requests to the Express backend on port 3001.

### `POST /api/interpret-intent`

Parses a natural language prompt into structured intent.

**Request:**
```json
{
  "prompt": "Create a poster for our college tech fest TechNova 2026 with a futuristic theme"
}
```

**Response:**
```json
{
  "type": "event_promotion",
  "title": "TechNova 2026",
  "description": "A futuristic-themed poster for a college technology festival",
  "audience": "college students and tech enthusiasts",
  "tone": "energetic",
  "elements": ["hero headline", "event date", "registration CTA", "tech visuals", "speaker lineup"],
  "rawPrompt": "Create a poster for our college tech fest..."
}
```

---

### `POST /api/generate-pipeline`

Creates an ordered execution plan from the parsed intent.

**Request:**
```json
{
  "intent": { ... }
}
```

**Response:**
```json
{
  "id": "uuid",
  "intentId": "TechNova 2026",
  "steps": [
    {
      "id": "uuid-step-0",
      "label": "Event Copy & Messaging",
      "description": "Generate headlines, taglines, and promotional copy",
      "stepType": "text",
      "status": "pending",
      "dependencies": [],
      "order": 1
    },
    {
      "id": "uuid-step-1",
      "label": "Visual Design System",
      "description": "Define color palette, typography, and layout",
      "stepType": "design",
      "status": "pending",
      "dependencies": ["uuid-step-0"],
      "order": 2
    },
    {
      "id": "uuid-step-2",
      "label": "Poster HTML/CSS",
      "description": "Generate the complete poster as HTML with inline styles",
      "stepType": "code",
      "status": "pending",
      "dependencies": ["uuid-step-1"],
      "order": 3
    }
  ],
  "createdAt": "2026-02-28T00:00:00.000Z"
}
```

---

### `POST /api/generate-asset`

Generates content for a single pipeline step.

**Request:**
```json
{
  "step": {
    "id": "uuid-step-0",
    "label": "Event Copy & Messaging",
    "description": "Generate headlines and promotional copy",
    "stepType": "text"
  },
  "intent": { ... }
}
```

**Response:**
```json
{
  "stepId": "uuid-step-0",
  "stepLabel": "Event Copy & Messaging",
  "content": "# TechNova 2026\n\n## Headline\n**The Future Starts Here**\n\n...",
  "contentType": "text",
  "explanation": "Generated text content for 'Event Copy & Messaging' using OpenAI GPT-4o-mini."
}
```

---

### `GET /api/health`

Health check endpoint.

```json
{
  "status": "ok",
  "timestamp": "2026-02-28T00:00:00.000Z"
}
```

---

## üóÇÔ∏è Project Structure

```
Campus-Os/
‚îú‚îÄ‚îÄ üìÑ index.html                 # Root HTML entry
‚îú‚îÄ‚îÄ üìÑ package.json               # Frontend dependencies & scripts
‚îú‚îÄ‚îÄ üìÑ vite.config.ts             # Vite config (React SWC + API proxy)
‚îú‚îÄ‚îÄ üìÑ tailwind.config.ts         # Tailwind with custom animations
‚îú‚îÄ‚îÄ üìÑ tsconfig.json              # TypeScript config
‚îú‚îÄ‚îÄ üìÑ README.md                  # ‚Üê You are here
‚îÇ
‚îú‚îÄ‚îÄ üìÅ public/
‚îÇ   ‚îî‚îÄ‚îÄ vite.svg                  # Gradient favicon
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docs/
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ screenshots/           # App screenshots
‚îÇ       ‚îú‚îÄ‚îÄ homepage.png
‚îÇ       ‚îú‚îÄ‚îÄ create-page.png
‚îÇ       ‚îî‚îÄ‚îÄ history-page.png
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                       # ‚îÄ‚îÄ Frontend ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ   ‚îú‚îÄ‚îÄ main.tsx                  # React entry point
‚îÇ   ‚îú‚îÄ‚îÄ App.tsx                   # Router + layout shell
‚îÇ   ‚îú‚îÄ‚îÄ index.css                 # Design system (glassmorphism, gradients)
‚îÇ   ‚îú‚îÄ‚îÄ vite-env.d.ts             # Vite type declarations
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Header.tsx            # Glassmorphic nav with active route indicator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IntentInput.tsx       # Prompt textarea + example prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IntentSummary.tsx     # Parsed intent display card
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PipelineView.tsx      # Step-by-step progress tracker
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AssetCard.tsx         # Output card (preview/copy/download)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CreationCanvas.tsx    # Orchestrates the creation flow UI
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ ui/               # shadcn/ui primitives
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ button.tsx        # Button with glow variant
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ card.tsx          # Card components
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ textarea.tsx      # Text input
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ badge.tsx         # Badge with glow variant
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ progress.tsx      # Gradient progress bar
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ separator.tsx     # Visual separator
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ scroll-area.tsx   # Custom scrollbar
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ skeleton.tsx      # Loading skeleton
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ toaster.tsx       # Toast notifications
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ pages/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Home.tsx              # Hero + features + creation types
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Create.tsx            # Main creation orchestration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ History.tsx           # Past creations list
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ NotFound.tsx          # 404 page
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.ts                # Typed REST client for backend
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ hooks/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useCreationEngine.ts  # Core state machine hook
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ types/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ campusos.ts           # TypeScript interfaces
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ lib/
‚îÇ       ‚îî‚îÄ‚îÄ utils.ts              # cn() class merge utility
‚îÇ
‚îî‚îÄ‚îÄ üìÅ server/                    # ‚îÄ‚îÄ Backend ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îú‚îÄ‚îÄ package.json              # Server dependencies
    ‚îú‚îÄ‚îÄ server.js                 # Express entry (CORS, routes)
    ‚îú‚îÄ‚îÄ .env                      # OPENAI_API_KEY (git-ignored)
    ‚îú‚îÄ‚îÄ .env.example              # Template for .env
    ‚îÇ
    ‚îú‚îÄ‚îÄ üìÅ lib/
    ‚îÇ   ‚îî‚îÄ‚îÄ openai.js             # Shared OpenAI client instance
    ‚îÇ
    ‚îî‚îÄ‚îÄ üìÅ routes/
        ‚îú‚îÄ‚îÄ interpret.js          # POST /api/interpret-intent
        ‚îú‚îÄ‚îÄ pipeline.js           # POST /api/generate-pipeline
        ‚îî‚îÄ‚îÄ asset.js              # POST /api/generate-asset
```

---

## üß© Tech Stack Deep Dive

### Frontend

| Technology | Version | Purpose |
|-----------|---------|---------|
| **React** | 18.3 | Component UI framework |
| **TypeScript** | 5.8 | Type safety |
| **Vite** | 5.4 | Dev server + build tool |
| **TailwindCSS** | 3.4 | Utility-first CSS |
| **shadcn/ui** | ‚Äî | Accessible UI primitives |
| **Framer Motion** | 11.x | Page & component animations |
| **React Router** | 6.30 | Client-side routing |
| **React Markdown** | 10.x | Render design spec output |
| **Sonner** | 1.7 | Toast notifications |
| **Lucide React** | 0.462 | Icons |

### Backend

| Technology | Version | Purpose |
|-----------|---------|---------|
| **Express.js** | 4.21 | HTTP server |
| **OpenAI SDK** | 4.77 | GPT-4o-mini API calls |
| **CORS** | 2.8 | Cross-origin support |
| **dotenv** | 16.4 | Environment variables |

### Design System

- **Dark mode** by default (CSS variables)
- **Glassmorphism** (`backdrop-filter: blur`)
- **Gradient text** (purple ‚Üí indigo ‚Üí blue)
- **Glow effects** on interactive elements
- **Grid background** pattern
- **Shimmer** loading animation
- **Custom scrollbar** styling
- **Inter** font family (Google Fonts)

---

## üîß Development

### Environment Variables

| Variable | Location | Description |
|----------|----------|-------------|
| `OPENAI_API_KEY` | `server/.env` | Your OpenAI API key (required for all AI features) |

### Available Scripts

| Command | Description |
|---------|-------------|
| `npm run dev` | Start Vite dev server (port 5173) |
| `npm run build` | Production build |
| `npm run preview` | Preview production build |
| `npm run server` | Start Express backend (port 3001) |
| `npm run dev:all` | Run both servers concurrently |

### API Proxy

The Vite dev server proxies all `/api/*` requests to `http://localhost:3001`. This means:
- Frontend: `http://localhost:5173`
- Backend: `http://localhost:3001`
- API calls from the frontend go through Vite ‚Üí Express seamlessly

---

## üìä Data Flow Sequence

Complete request lifecycle for generating a poster:

```mermaid
sequenceDiagram
    actor User
    participant UI as React Frontend
    participant Hook as useCreationEngine
    participant API as Express Server
    participant GPT as OpenAI GPT-4o-mini

    User->>UI: Types "Create a tech fest poster"
    UI->>Hook: onSubmit(prompt)
    Hook->>Hook: status ‚Üí "interpreting"
    
    Hook->>API: POST /api/interpret-intent
    API->>GPT: Chat completion (JSON mode)
    GPT-->>API: ParsedIntent JSON
    API-->>Hook: { type, title, audience, ... }
    Hook->>Hook: status ‚Üí "planning"
    
    Hook->>API: POST /api/generate-pipeline
    API->>GPT: Chat completion (JSON mode)
    GPT-->>API: Pipeline steps JSON
    API-->>Hook: { steps: [...] }
    Hook->>Hook: status ‚Üí "generating"
    
    loop For each pipeline step
        Hook->>Hook: step.status ‚Üí "running"
        Hook->>API: POST /api/generate-asset
        API->>GPT: Chat completion (text/design/code)
        GPT-->>API: Generated content
        API-->>Hook: { content, contentType }
        Hook->>Hook: step.status ‚Üí "done"
        Hook->>UI: Re-render with new asset
    end
    
    Hook->>Hook: status ‚Üí "done"
    Hook->>Hook: Save to localStorage
    UI->>User: Display all generated assets
```

---

## üîê Security Notes

- API keys are stored in `server/.env` (git-ignored)
- The OpenAI key is **never exposed to the frontend**
- All AI calls go through the Express backend
- CORS is restricted to `localhost` origins

---

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

---

## üìú License

This project is private and proprietary.

---

## üë§ Author

**Nitin OG** ‚Äî [@nitinog10](https://github.com/nitinog10)

---

<p align="center">
  Built with ‚ù§Ô∏è and OpenAI
</p>
